<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>An analysis of weighted on-base averages with ebnm • ebnm</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="An analysis of weighted on-base averages with ebnm">
<meta property="og:description" content="ebnm">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">ebnm</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.1-12</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/stephenslab/ebnm" class="external-link">Source</a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>An analysis of weighted on-base averages with
ebnm</h1>
                        <h4 data-toc-skip class="author">Jason
Willwersheid, Peter Carbonetto and Matthew Stephens</h4>
            
            <h4 data-toc-skip class="date">2024-02-26</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/stephenslab/ebnm/blob/HEAD/vignettes/baseball.Rmd" class="external-link"><code>vignettes/baseball.Rmd</code></a></small>
      <div class="hidden name"><code>baseball.Rmd</code></div>

    </div>

    
    
<p>In this vignette, we illustrate the key features of ebnm in an
analysis of some baseball statistics.</p>
<div class="section level2">
<h2 id="the-woba-data-set">The “wOBA” data set<a class="anchor" aria-label="anchor" href="#the-woba-data-set"></a>
</h2>
<p>We begin by loading and inspecting the wOBA data set, which consists
of wOBAs (“weighted on-base averages”) and standard errors for the 2022
MLB regular season:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/stephenslab/ebnm" class="external-link">ebnm</a></span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">)</span>
<span class="co"># [1] 688</span>
<span class="co">#   FanGraphsID           Name Team  PA     x     s</span>
<span class="co"># 1       19952     Khalil Lee  NYM   2 1.036 0.733</span>
<span class="co"># 2       16953 Chadwick Tromp  ATL   4 0.852 0.258</span>
<span class="co"># 3       19608     Otto Lopez  TOR  10 0.599 0.162</span>
<span class="co"># 4       24770   James Outman  LAD  16 0.584 0.151</span>
<span class="co"># 5        8090 Matt Carpenter  NYY 154 0.472 0.054</span>
<span class="co"># 6       15640    Aaron Judge  NYY 696 0.458 0.024</span></code></pre></div>
<p>Column “x” contains the observed wOBAs, which we interpret as
estimates of the players’ “true” wOBA skill. Column “s” gives the
standard errors. (See below for background on the wOBA statistic and
details on how the standard errors were calculated.)</p>
<p>Next, we visualize the overall distribution of wOBAs:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">wOBA</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html" class="external-link">geom_histogram</a></span><span class="op">(</span>bins <span class="op">=</span> <span class="fl">64</span>, color <span class="op">=</span> <span class="st">"white"</span>,fill <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_classic</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<p><img src="baseball_files/figure-html/woba-histogram-1.png" width="480" style="display: block; margin: auto;"></p>
<p>As the histogram shows, most players finished the season with a wOBA
between .200 and .400. A few had very high wOBAs (&gt;.500), while
others had wOBAs at or near zero. A casual inspection of the data
suggests that players with these very high (or very low) wOBAs were
simply lucky (or unlucky). For example, the four players with the
highest wOBAs each had 16 PAs or fewer. It is unlikely that they would
have sustained this high level of production over a full season’s worth
of PAs!</p>
<p>In contrast, Aaron Judge’s production — which included a
record-breaking number of home runs — appears to be “real,” since it was
sustained over nearly 700 PAs. Other cases are more ambiguous: how, for
example, are we to assess Matt Carpenter, who had several exceptional
seasons between 2013 and 2018 but whose output steeply declined in
2019–2021 before his surprising “comeback” in 2022? An empirical Bayes
analysis can help to answer this and other questions.</p>
</div>
<div class="section level2">
<h2 id="the-ebnm-function">The “ebnm” function<a class="anchor" aria-label="anchor" href="#the-ebnm-function"></a>
</h2>
<p>Function <code><a href="../reference/ebnm.html">ebnm()</a></code> is the main interface for fitting the
empirical Bayes normal means model; it is a “Swiss army knife” that
allows for various choices of prior family <span class="math inline">\(\mathcal{G}\)</span> as well as providing multiple
options for fitting and tuning models. For example, we can fit a normal
means model with the prior family <span class="math inline">\(\mathcal{G}\)</span> taken to be the family of
normal distributions:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">x</span>
<span class="va">s</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">s</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">Name</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">s</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="va">wOBA</span><span class="op">$</span><span class="va">Name</span>
<span class="va">fit_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"normal"</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></code></pre></div>
<p>(The default behavior is to fix the prior mode at zero. Since we
certainly do not expect the distribution of true wOBA skill to have a
mode at zero, we set <code>mode = "estimate"</code>.)</p>
<p>We note in passing that the <code>ebnm</code> package has a second
model-fitting interface, in which each prior family gets its own
function:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_normal.html">ebnm_normal</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></code></pre></div>
<p>Textual and graphical overviews of results can be obtained using,
respectively, methods <code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> and <code><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot()</a></code>.
The summary method appears as follows:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span>
<span class="co"># </span>
<span class="co"># Call:</span>
<span class="co"># ebnm_normal(x = x, s = s, mode = "estimate")</span>
<span class="co"># </span>
<span class="co"># EBNM model was fitted to 688 observations with _heteroskedastic_ standard errors.</span>
<span class="co"># </span>
<span class="co"># The fitted prior belongs to the _normal_ prior family.</span>
<span class="co"># </span>
<span class="co"># 2 degrees of freedom were used to estimate the model.</span>
<span class="co"># The log likelihood is 989.64.</span>
<span class="co"># </span>
<span class="co"># Available posterior summaries: _mean_, _sd_.</span>
<span class="co"># Use method fitted() to access available summaries.</span>
<span class="co"># </span>
<span class="co"># A posterior sampler is _not_ available.</span>
<span class="co"># One can be added via function ebnm_add_sampler().</span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot()</a></code> method visualizes results, comparing the
“observed” values <span class="math inline">\(x_i\)</span> (the initial
wOBA estimates) against the empirical Bayes posterior mean estimates
<span class="math inline">\(\hat{\theta}_i\)</span>:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span></code></pre></div>
<p><img src="baseball_files/figure-html/plot-ebnm-normal-1.png" width="372" style="display: block; margin: auto;"></p>
<p>The dashed line shows the diagonal <span class="math inline">\(x =
y\)</span>, which makes shrinkage effects clearly visible. In
particular, the most extreme wOBAs on either end of the spectrum are
strongly shrunk towards the league average (around .300).</p>
<p>Since <code><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot()</a></code> returns a “ggplot” object <span class="citation">(Wickham 2016)</span>, the plot can conveniently be
customized using <code>ggplot2</code> syntax. For example, one can vary
the color of the points by the number of plate appearances:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">$</span><span class="va">PA</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"wOBA"</span>, y <span class="op">=</span> <span class="st">"EB estimate of true wOBA skill"</span>, 
       color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">PA</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_gradient.html" class="external-link">scale_color_gradient</a></span><span class="op">(</span>low <span class="op">=</span> <span class="st">"blue"</span>, high <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></code></pre></div>
<p><img src="baseball_files/figure-html/plot-ebnm-normal-better-1.png" width="444" style="display: block; margin: auto;"></p>
<p>By varying the color of points, we see that the wOBA estimates with
higher standard errors or fewer plate appearances (blue points) tend to
be shrunk toward the league average much more strongly than wOBAs from
hitters with many plate appearances (red points).</p>
<p>Above, we used <code><a href="https://rdrr.io/r/utils/head.html" class="external-link">head()</a></code> to view data for the first 6
hitters in the dataset. Let’s now see what the EBNM analysis suggests
might be their “true” wOBA skill. To examine the results more closely,
we use the <code><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted()</a></code> method, which returns a posterior
summary for each hitter:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="co">#                 mean     sd</span>
<span class="co"># Khalil Lee     0.303 0.0287</span>
<span class="co"># Chadwick Tromp 0.308 0.0286</span>
<span class="co"># Otto Lopez     0.310 0.0283</span>
<span class="co"># James Outman   0.311 0.0282</span>
<span class="co"># Matt Carpenter 0.339 0.0254</span>
<span class="co"># Aaron Judge    0.394 0.0184</span></code></pre></div>
<p>The wOBA estimates of the first four ballplayers are shrunk strongly
toward the league average, reflecting the fact that these players had
very few plate appearances (and indeed, we were not swayed by their very
high initial wOBA estimates).</p>
<p>Carpenter had many more plate appearances (154) than these other four
players, but according to this model we should remain skeptical about
his strong performance; after factoring in the prior, we judge his
“true” performance to be much closer to the league average, downgrading
an initial estimate of .472 to the final posterior mean estimate of
.339.</p>
</div>
<div class="section level2">
<h2 id="comparing-different-priors">Comparing different priors<a class="anchor" aria-label="anchor" href="#comparing-different-priors"></a>
</h2>
<p>Judge’s “true” wOBA is also estimated to be much lower (.394) than
the initial estimate (.458) despite sustaining a high level of
production over a full season (696 PAs). For this reason, one might ask
whether a prior that is more flexible than the normal prior — that is, a
prior that can better adapt to “outliers” like Judge — might produce a
different result. The ebnm package is very well suited to answering this
question. For example, to obtain results using the family of all
unimodal distributions rather than the family of normal distributions,
we only need to change “prior_family” from “normal” to “unimodal”:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_unimodal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"unimodal"</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></code></pre></div>
<p>It is straightforward to produce a side-by-side visualization of the
fitted models simply by including both models as arguments to the
<code><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot()</a></code> method (we also use the “subset” argument to focus
on the results for Judge and other players with the most plate
appearances):</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">top50</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/order.html" class="external-link">order</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">$</span><span class="va">PA</span>, decreasing <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">top50</span> <span class="op">&lt;-</span> <span class="va">top50</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">50</span><span class="op">]</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, subset <span class="op">=</span> <span class="va">top50</span><span class="op">)</span></code></pre></div>
<p><img src="baseball_files/figure-html/ebnm-normal-vs-unimodal-1.png" width="540" style="display: block; margin: auto;"></p>
<p>This plot illustrates the ability of the unimodal prior to better
adapt to the data: wOBA estimates for players with a lot of plate
appearances are not adjusted quite so strongly toward the league
average. To compare in more detail, we see for example that Judge’s wOBA
estimate from the model with the unimodal prior (the “mean2” column)
remains much closer to the original wOBA estimate:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">wOBA</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"PA"</span>,<span class="st">"x"</span><span class="op">)</span><span class="op">]</span>,
             <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span>,
             <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html" class="external-link">fitted</a></span><span class="op">(</span><span class="va">fit_unimodal</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"PA"</span>, <span class="st">"x"</span>, <span class="st">"mean1"</span>, <span class="st">"sd1"</span>, <span class="st">"mean2"</span>, <span class="st">"sd2"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">dat</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="co">#                 PA     x mean1    sd1 mean2    sd2</span>
<span class="co"># Khalil Lee       2 1.036 0.303 0.0287 0.302 0.0277</span>
<span class="co"># Chadwick Tromp   4 0.852 0.308 0.0286 0.307 0.0306</span>
<span class="co"># Otto Lopez      10 0.599 0.310 0.0283 0.310 0.0315</span>
<span class="co"># James Outman    16 0.584 0.311 0.0282 0.311 0.0318</span>
<span class="co"># Matt Carpenter 154 0.472 0.339 0.0254 0.355 0.0430</span>
<span class="co"># Aaron Judge    696 0.458 0.394 0.0184 0.439 0.0155</span></code></pre></div>
<p>Carpenter’s wOBA estimate is also higher under the more flexible
unimodal prior, but is still adjusted much more than Judge’s in light of
Carpenter’s smaller sample size. It is also interesting that the
unimodal prior assigns greater uncertainty (the “sd2” column) to this
estimate compared to the normal prior.</p>
<p>Recall that the two normal means models differ only in the priors
used, so we can understand the differences in the shrinkage behavior of
these models by inspecting the priors. Calling <code><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot()</a></code> with
<code>incl_cdf = TRUE</code> shows the cumulative distribution functions
(CDFs) of the fitted priors <span class="math inline">\(\hat{g}\)</span>. Since we are particularly
interested in understanding the differences in shrinkage behaviour for
the largest wOBAs such as Judge’s, we create a second plot that zooms in
on wOBAs over .350:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://wilkelab.org/cowplot/" class="external-link">cowplot</a></span><span class="op">)</span>
<span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, incl_pm <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html" class="external-link">xlim</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.250</span>, <span class="fl">.350</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/guides.html" class="external-link">guides</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span>
<span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, incl_pm <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html" class="external-link">lims</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">.350</span>, <span class="fl">.450</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.95</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://wilkelab.org/cowplot/reference/plot_grid.html" class="external-link">plot_grid</a></span><span class="op">(</span><span class="va">p1</span>, <span class="va">p2</span>, nrow <span class="op">=</span> <span class="fl">1</span>, ncol <span class="op">=</span> <span class="fl">2</span>, rel_widths <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p><img src="baseball_files/figure-html/ebnm-normal-vs-unimodal-3-1.png" width="780" style="display: block; margin: auto;"></p>
<p>The plot on the right shows that the fitted normal prior has almost
no mass on wOBAs above .400, explaining why Judge’s wOBA estimate is
shrunk so strongly toward the league average, whereas the unimodal prior
is flexible enough to permit larger posterior estimates above .400.</p>
<p>The posterior means and standard errors returned from the
<code><a href="../reference/ebnm.html">ebnm()</a></code> call cannot be used to obtain credible intervals
(except for the special case of the normal prior). Therefore, we provide
additional methods <code><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint()</a></code> and <code><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile()</a></code>
which return, respectively, credible intervals — or, more precisely,
<em>highest posterior density</em> intervals <span class="citation">(Chen and Shao 1999)</span> — and posterior quantiles
for each observation. These are implemented using Monte Carlo
techniques, which can be slow for large data sets, so credible intervals
are not computed by default. The following code computes 80% highest
posterior density (HPD) intervals for the EBNM model with unimodal
prior. [We add a Monte Carlo sampler using function
<code><a href="../reference/ebnm_add_sampler.html">ebnm_add_sampler()</a></code>; alternatively, we could have added a
sampler in our initial calls to <code><a href="../reference/ebnm.html">ebnm()</a></code> by specifying
<code>output = output_all()</code>.] We set a seed for
reproducibility:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_unimodal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_add_sampler.html">ebnm_add_sampler</a></span><span class="op">(</span><span class="va">fit_unimodal</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit_unimodal</span>, level <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="co">#                CI.lower CI.upper</span>
<span class="co"># Khalil Lee        0.277    0.328</span>
<span class="co"># Chadwick Tromp    0.277    0.334</span>
<span class="co"># Otto Lopez        0.277    0.336</span>
<span class="co"># James Outman      0.277    0.335</span>
<span class="co"># Matt Carpenter    0.277    0.389</span>
<span class="co"># Aaron Judge       0.428    0.458</span></code></pre></div>
<p>Interestingly, the 80% credible interval for Carpenter is very wide,
and shares the same lower bound as the first four ballplayers with very
few plate appearances.</p>
</div>
<div class="section level2">
<h2 id="reanalyzing-the-data-using-a-nonparametric-prior">Reanalyzing the data using a nonparametric prior<a class="anchor" aria-label="anchor" href="#reanalyzing-the-data-using-a-nonparametric-prior"></a>
</h2>
<p>Above, we demonstrated how the <code>ebnm</code> package makes it is
easy to perform EBNM analyses with different types of priors, then
compared results across two different choices of prior family. Each of
these families makes different assumptions about the data which, <em>a
priori</em>, may be more or less plausible. An alternative to prior
families that make specific assumptions about the data is to use the
prior family that contains <em>all</em> distributions <span class="math inline">\(\mathcal{G}_{\mathrm{npmle}}\)</span>, which is in
a sense “assumption free.” Here we re-analyze the wOBA data set to
illustrate the use of this prior family. Note that although
nonparametric priors require specialized computational techniques,
switching to a nonparametric prior is seamless in ebnm, as these
implementation details are hidden. Similar to above, we need only make a
single change to the <code>prior_family</code> argument:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"npmle"</span><span class="op">)</span></code></pre></div>
<p>(Note that because the family <span class="math inline">\(\mathcal{G}_{\mathrm{npmle}}\)</span> is not
unimodal, the <code>mode = "estimate"</code> option is not relevant
here.)</p>
<p>Although the implementation details are hidden by default, it can
sometimes be helpful to see what is going on “behind the scenes,”
particularly for flagging or diagnosing issues. By default, ebnm uses
the mixsqp package <span class="citation">(Kim et al. 2020)</span> to
fit the NPMLE <span class="math inline">\(\hat{g} \in
\mathcal{G}_{\mathrm{npmle}}\)</span>. We can monitor convergence of the
mix-SQP optimization algorithm by setting the “verbose” control argument
to “TRUE”:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"npmle"</span>, 
                  control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>
<span class="co"># Running mix-SQP algorithm 0.3-48 on 688 x 95 matrix</span>
<span class="co"># convergence tol. (SQP):     1.0e-08</span>
<span class="co"># conv. tol. (active-set):    1.0e-10</span>
<span class="co"># zero threshold (solution):  1.0e-08</span>
<span class="co"># zero thresh. (search dir.): 1.0e-14</span>
<span class="co"># l.s. sufficient decrease:   1.0e-02</span>
<span class="co"># step size reduction factor: 7.5e-01</span>
<span class="co"># minimum step size:          1.0e-08</span>
<span class="co"># max. iter (SQP):            1000</span>
<span class="co"># max. iter (active-set):     20</span>
<span class="co"># number of EM iterations:    10</span>
<span class="co"># Computing SVD of 688 x 95 matrix.</span>
<span class="co"># Matrix is not low-rank; falling back to full matrix.</span>
<span class="co"># iter        objective max(rdual) nnz stepsize max.diff nqp nls</span>
<span class="co">#    1 +9.583407733e-01  -- EM --   95 1.00e+00 6.08e-02  --  --</span>
<span class="co">#    2 +8.298700300e-01  -- EM --   95 1.00e+00 2.87e-02  --  --</span>
<span class="co">#    3 +7.955308369e-01  -- EM --   95 1.00e+00 1.60e-02  --  --</span>
<span class="co">#    4 +7.819858634e-01  -- EM --   68 1.00e+00 1.05e-02  --  --</span>
<span class="co">#    5 +7.753787534e-01  -- EM --   53 1.00e+00 7.57e-03  --  --</span>
<span class="co">#    6 +7.717040208e-01  -- EM --   49 1.00e+00 5.73e-03  --  --</span>
<span class="co">#    7 +7.694760705e-01  -- EM --   47 1.00e+00 4.48e-03  --  --</span>
<span class="co">#    8 +7.680398878e-01  -- EM --   47 1.00e+00 3.58e-03  --  --</span>
<span class="co">#    9 +7.670690681e-01  -- EM --   44 1.00e+00 2.91e-03  --  --</span>
<span class="co">#   10 +7.663865515e-01  -- EM --   42 1.00e+00 2.40e-03  --  --</span>
<span class="co">#    1 +7.658902386e-01 +6.493e-02  39  ------   ------   --  --</span>
<span class="co">#    2 +7.655151741e-01 +5.328e-02  19 1.00e+00 1.29e-01  20   1</span>
<span class="co">#    3 +7.627792563e-01 +6.432e-03   7 1.00e+00 1.74e-01  20   1</span>
<span class="co">#    4 +7.626270812e-01 +5.897e-05   7 1.00e+00 3.23e-01   7   1</span>
<span class="co">#    5 +7.626270755e-01 -1.335e-08   7 1.00e+00 4.67e-04   2   1</span>
<span class="co"># Optimization took 0.03 seconds.</span>
<span class="co"># Convergence criteria met---optimal solution found.</span></code></pre></div>
<p>This output shows no issues with convergence of the optimization
algorithm; the mix-SQP algorithm converged to the solution (up to
numerical rounding error) in only 6 iterations. In some cases,
convergence issues can arise when fitting nonparametric models to large
or complex data sets, and revealing the details of the optimization can
help to pinpoint these issues.</p>
<p>Next, we visually compare the three fits obtained so far:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_normal</span>, <span class="va">fit_unimodal</span>, <span class="va">fit_npmle</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, subset <span class="op">=</span> <span class="va">top50</span><span class="op">)</span></code></pre></div>
<p><img src="baseball_files/figure-html/plot-npmle-1.png" width="510" style="display: block; margin: auto;"><img src="baseball_files/figure-html/plot-npmle-2.png" width="510" style="display: block; margin: auto;"></p>
<p>As before, estimates largely agree, differing primarily at the tails.
Both the unimodal prior family and the NPMLE are sufficiently flexible
to avoid the strong shrinkage behavior of the normal prior family.</p>
<p>Fits can be compared quantitatively using the <code><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik()</a></code>
method, which, in addition to the log likelihood for each model,
usefully reports the number of free parameters (i.e., degrees of
freedom):</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_unimodal</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_npmle</span><span class="op">)</span>
<span class="co"># 'log Lik.' 992.6578 (df=40)</span>
<span class="co"># 'log Lik.' 994.193 (df=94)</span></code></pre></div>
<p>A nonparametric prior <span class="math inline">\(\mathcal{G}\)</span> is approximated by <span class="math inline">\(K\)</span> mixture components on a fixed grid,
with the mixture proportions to be estimated. We can infer from the
above output that <span class="math inline">\(\mathcal{G}_\text{npmle}\)</span> has been
approximated as a family of mixtures over a grid of <span class="math inline">\(K = 95\)</span> point masses spanning the range of
the data. (The number of degrees of freedom is one fewer than <span class="math inline">\(K\)</span> because the mixture proportions must
always sum to 1, which removes one degree of freedom from the estimation
of <span class="math inline">\({\boldsymbol\pi}\)</span>.)</p>
<p>The default behaviour for nonparametric prior families is to choose
<span class="math inline">\(K\)</span> such that the likelihood obtained
using estimate <span class="math inline">\(\hat{g}\)</span> should be
(on average) within one log-likelihood unit of the optimal estimate from
among the entire nonparametric family <span class="math inline">\(\mathcal{G}\)</span> <span class="citation">(see
Willwerscheid 2021)</span>. Thus, a finer approximating grid should not
yield a large improvement in the log-likelihood. We can check this by
using <code><a href="../reference/ebnm_scale_npmle.html">ebnm_scale_npmle()</a></code> to create a finer grid:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">scale_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_scale_npmle.html">ebnm_scale_npmle</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, KLdiv_target <span class="op">=</span> <span class="fl">0.001</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, 
                                max_K <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span>
<span class="va">fit_npmle_finer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_npmle.html">ebnm_npmle</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, scale <span class="op">=</span> <span class="va">scale_npmle</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_npmle</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">fit_npmle_finer</span><span class="op">)</span>
<span class="co"># 'log Lik.' 994.193 (df=94)</span>
<span class="co"># 'log Lik.' 994.2703 (df=528)</span></code></pre></div>
<p>As the theory predicts, a much finer grid, with <span class="math inline">\(K = 529\)</span>, results in only a modest
improvement in the log-likelihood. ebnm provides similar functions to
customize grids for unimodal and normal scale mixture prior
families.</p>
<p>One potential issue with the NPMLE is that, since it is discrete (as
the above CDF plot makes apparent), observations are variously shrunk
towards one of the support points, which can result in poor interval
estimates. For illustration, we calculate 10% and 90% quantiles:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_npmle</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_add_sampler.html">ebnm_add_sampler</a></span><span class="op">(</span><span class="va">fit_npmle</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile</a></span><span class="op">(</span><span class="va">fit_npmle</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="co">#                  10%   90%</span>
<span class="co"># Khalil Lee     0.276 0.342</span>
<span class="co"># Chadwick Tromp 0.276 0.342</span>
<span class="co"># Otto Lopez     0.276 0.342</span>
<span class="co"># James Outman   0.276 0.342</span>
<span class="co"># Matt Carpenter 0.309 0.430</span>
<span class="co"># Aaron Judge    0.419 0.430</span></code></pre></div>
<p>Each credible interval bound is constrained to lie at one of the
support points of the NPMLE <span class="math inline">\(\hat{g}\)</span>. The interval estimate for Judge
strikes us as far too narrow. Indeed, the NPMLE can sometimes yield
degenerate interval estimates:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">fit_npmle</span>, level <span class="op">=</span> <span class="fl">0.8</span>, parm <span class="op">=</span> <span class="st">"Aaron Judge"</span><span class="op">)</span>
<span class="co">#              CI.lower  CI.upper</span>
<span class="co"># Aaron Judge 0.4298298 0.4298298</span></code></pre></div>
<p>To address this issue, the deconvolveR package <span class="citation">(Narasimhan and Efron 2020)</span> uses a penalized
likelihood that encourages “smooth” priors <span class="math inline">\(\hat{g}\)</span>; that is, priors <span class="math inline">\(\hat{g}\)</span> for which few of the mixture
proportions are zero:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_deconv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm_deconvolver.html">ebnm_deconvolver</a></span><span class="op">(</span><span class="va">x</span> <span class="op">/</span> <span class="va">s</span>, output <span class="op">=</span> <span class="fu"><a href="../reference/ebnm.html">ebnm_output_all</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> 
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fit_deconv</span>, incl_cdf <span class="op">=</span> <span class="cn">TRUE</span>, incl_pm <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<p><img src="baseball_files/figure-html/ebnm-deconvolver-1.png" width="300" style="display: block; margin: auto;"></p>
<p>Note, however, that the “true” means being estimated are <span class="math inline">\(z\)</span>-scores rather than raw wOBA skill, as
package deconvolveR fits a model to z-scores rather than observations
and associated standard errors. While this is reasonable in many
settings, it does not seem appropriate for the present analysis:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html" class="external-link">quantile</a></span><span class="op">(</span><span class="va">fit_deconv</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span> <span class="op">*</span> <span class="va">s</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="co">#                  10%   90%</span>
<span class="co"># Khalil Lee     0.400 2.000</span>
<span class="co"># Chadwick Tromp 0.563 1.127</span>
<span class="co"># Otto Lopez     0.354 0.796</span>
<span class="co"># James Outman   0.412 0.742</span>
<span class="co"># Matt Carpenter 0.413 0.531</span>
<span class="co"># Aaron Judge    0.406 0.459</span></code></pre></div>
<p>These interval estimates do not match our basic intuitions; for
example, a wOBA over .600 has never been sustained over a full
season.</p>
</div>
<div class="section level2">
<h2 id="background-on-the-weighted-on-base-average">Background on the “weighted on-base average”<a class="anchor" aria-label="anchor" href="#background-on-the-weighted-on-base-average"></a>
</h2>
<p>A longstanding tradition in empirical Bayes research is to include an
analysis of batting averages using data from Major League Baseball; see,
for example, <span class="citation">Brown (2008)</span>; <span class="citation">Jiang and Zhang (2010)</span>; <span class="citation">Gu and Koenker (2017)</span>. Until recently, batting
averages were the most important measurement of a hitter’s performance,
with the prestigious yearly “batting title” going to the hitter with the
highest average. However, with the rise of baseball analytics, metrics
that better correlate to teams’ overall run production have become
increasingly preferred. One such metric is wOBA (“weighted on-base
average”), which is both an excellent measure of a hitter’s offensive
production and, unlike competing metrics such as MLB’s xwOBA <span class="citation">(Sharpe 2019)</span> or Baseball Prospectus’s DRC+
<span class="citation">(Judge 2019)</span>, can be calculated using
publicly available data and methods.</p>
<p>Initially proposed by <span class="citation">Tango, Lichtman, and
Dolphin (2006)</span>, wOBA assigns values (“weights”) to hitting
outcomes according to how much the outcome contributes on average to run
production. For example, while batting average treats singles
identically to home runs, wOBA gives a hitter more than twice as much
credit for a home run. (Note that weights are updated from year to year,
but wOBA weights for singles have remained near 0.9 for the last several
decades, while weights for home runs have hovered around 2.0; see <span class="citation">FanGraphs (2023)</span>.)</p>
<p>Given a vector of wOBA weights <span class="math inline">\(\mathbf{w}\)</span>, hitter <span class="math inline">\(i\)</span>’s wOBA is the weighted average <span class="math display">\[
x_i = \mathbf{w}^\top \mathbf{z}^{(i)} / n_i,
\]</span> where <span class="math inline">\(\mathbf{z}^{(i)} =
(z_1^{(i)}, \ldots, z_7^{(i)})\)</span> tallies outcomes (singles,
doubles, triples, home runs, walks, hit-by-pitches and outs) over the
hitter’s <span class="math inline">\(n_i\)</span> plate appearances
(PAs). Modeling hitting outcomes as i.i.d. <span class="math display">\[
\mathbf{z}^{(i)} \sim \text{Multinomial}(n_i, \mathbf{\pi}^{(i)}),
\]</span> where <span class="math inline">\(\mathbf{\pi}^{(i)} = (\pi_1,
\ldots, \pi_7^{(i)})\)</span> is the vector of “true” outcome
probabilities for hitter <span class="math inline">\(i\)</span>, we can
regard <span class="math inline">\(x_i\)</span> as a point estimate for
the hitter’s “true wOBA skill”, <span class="math display">\[
\theta_i = \mathbf{w}^\top \mathbf{\pi}^{(i)}.
\]</span> Standard errors for the <span class="math inline">\(x_i\)</span>’s can be estimated as <span class="math display">\[
s_i^2 = \mathbf{w}^\top \hat{\mathbf{\Sigma}}^{(i)} \mathbf{w}/n_i,
\]</span> where <span class="math inline">\(\hat{\mathbf{\Sigma}}^{(i)}\)</span> is the
estimate of the covariance matrix for the multinomial model obtained by
setting <span class="math inline">\(\mathbf{\pi} =
\hat{\mathbf{\pi}}\)</span>, where <span class="math display">\[
\hat{\mathbf{\pi}}^{(i)} = \mathbf{z}^{(i)}/n_i.
\]</span> (To deal with small sample sizes, we conservatively lower
bound each standard error by the standard error that would be obtained
by plugging in league-average event probabilities <span class="math inline">\(\hat{\mathbf{\pi}}_{\mathrm{lg}} = \sum_{i=1}^N
\mathbf{z}^{(i)}/ \sum_{i=1}^N n_i\)</span>, where <span class="math inline">\(N\)</span> is the number of hitters in the data
set.)</p>
<p>The relative complexity of wOBA makes it well suited for analysis via
ebnm. With batting average, a common approach is to obtain empirical
Bayes estimates using a beta-binomial model (see, for example, <span class="citation">Robinson (2017)</span>). With wOBA, one can estimate
hitting outcome probabilities by way of a Dirichlet-multinomial model;
alternatively, one can approximate the likelihood as normal and fit an
EBNM model directly to the observed wOBAs. We take the latter
approach.</p>
</div>
<div class="section level2">
<h2 id="session-information">Session information<a class="anchor" aria-label="anchor" href="#session-information"></a>
</h2>
<p>The following R version and packages were used to generate this
vignette:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html" class="external-link">sessionInfo</a></span><span class="op">(</span><span class="op">)</span>
<span class="co"># R version 3.6.2 (2019-12-12)</span>
<span class="co"># Platform: x86_64-apple-darwin15.6.0 (64-bit)</span>
<span class="co"># Running under: macOS Catalina 10.15.7</span>
<span class="co"># </span>
<span class="co"># Matrix products: default</span>
<span class="co"># BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib</span>
<span class="co"># LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib</span>
<span class="co"># </span>
<span class="co"># locale:</span>
<span class="co"># [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8</span>
<span class="co"># </span>
<span class="co"># attached base packages:</span>
<span class="co"># [1] stats     graphics  grDevices utils     datasets  methods   base     </span>
<span class="co"># </span>
<span class="co"># other attached packages:</span>
<span class="co"># [1] cowplot_1.1.1 ggplot2_3.3.6 ebnm_1.1-12  </span>
<span class="co"># </span>
<span class="co"># loaded via a namespace (and not attached):</span>
<span class="co">#  [1] Rcpp_1.0.8         horseshoe_0.2.0    invgamma_1.1       lattice_0.20-38   </span>
<span class="co">#  [5] assertthat_0.2.1   rprojroot_2.0.3    digest_0.6.23      utf8_1.1.4        </span>
<span class="co">#  [9] truncnorm_1.0-8    R6_2.4.1           evaluate_0.14      highr_0.8         </span>
<span class="co"># [13] pillar_1.6.2       rlang_1.0.6        irlba_2.3.3        jquerylib_0.1.4   </span>
<span class="co"># [17] Matrix_1.3-4       rmarkdown_2.21     pkgdown_2.0.7      desc_1.2.0        </span>
<span class="co"># [21] labeling_0.3       splines_3.6.2      stringr_1.4.0      munsell_0.5.0     </span>
<span class="co"># [25] mixsqp_0.3-48      compiler_3.6.2     xfun_0.36          pkgconfig_2.0.3   </span>
<span class="co"># [29] systemfonts_1.0.2  SQUAREM_2017.10-1  htmltools_0.5.4    tidyselect_1.1.1  </span>
<span class="co"># [33] tibble_3.1.3       fansi_0.4.0        crayon_1.4.1       dplyr_1.0.7       </span>
<span class="co"># [37] withr_2.5.0        grid_3.6.2         jsonlite_1.7.2     gtable_0.3.0      </span>
<span class="co"># [41] lifecycle_1.0.3    DBI_1.1.0          magrittr_2.0.1     scales_1.1.0      </span>
<span class="co"># [45] cli_3.5.0          stringi_1.4.3      farver_2.0.1       fs_1.5.2          </span>
<span class="co"># [49] bslib_0.3.1        ellipsis_0.3.2     ragg_0.3.1         generics_0.0.2    </span>
<span class="co"># [53] vctrs_0.3.8        trust_0.1-8        RColorBrewer_1.1-2 tools_3.6.2       </span>
<span class="co"># [57] glue_1.4.2         purrr_0.3.4        fastmap_1.1.0      yaml_2.2.0        </span>
<span class="co"># [61] colorspace_1.4-1   ashr_2.2-57        memoise_1.1.0      deconvolveR_1.2-1 </span>
<span class="co"># [65] knitr_1.37         sass_0.4.0</span></code></pre></div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="bibliography">Bibliography<a class="anchor" aria-label="anchor" href="#bibliography"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-BrownBaseball" class="csl-entry">
Brown, Lawrence D. 2008. <span>“In-Season Prediction of Batting
Averages: A Field Test of Empirical <span>B</span>ayes and
<span>B</span>ayes Methodologies.”</span> <em>Annals of Applied
Statistics</em> 2 (1): 113–52.
</div>
<div id="ref-chen-1999" class="csl-entry">
Chen, Ming-Hui, and Qi-Man Shao. 1999. <span>“<span>Monte</span>
<span>Carlo</span> Estimation of <span>Bayesian</span> Credible and
<span>HPD</span> Intervals.”</span> <em>Journal of Computational and
Graphical Statistics</em> 8 (1): 69–92.
</div>
<div id="ref-fgguts" class="csl-entry">
FanGraphs. 2023. <span>“Guts!”</span> <a href="https://www.fangraphs.com/guts.aspx" class="external-link">https://www.fangraphs.com/guts.aspx</a>.
</div>
<div id="ref-GuKoenkerBaseball" class="csl-entry">
Gu, Jiaying, and Roger Koenker. 2017. <span>“Empirical
<span>B</span>ayesball Remixed: Empirical <span>B</span>ayes Methods for
Longitudinal Data.”</span> <em>Journal of Applied Econometrics</em> 32
(3): 575–99.
</div>
<div id="ref-JiangZhangBaseball" class="csl-entry">
Jiang, Wenhua, and Cun-Hui Zhang. 2010. <span>“Empirical
<span>B</span>ayes <span>I</span>n-Season Prediction of Baseball Batting
Averages.”</span> In <em>Borrowing Strength: Theory Powering
Applications—a <span>F</span>estschrift for <span>L</span>awrence
<span>D</span>. <span>B</span>rown</em>, 6:263–73. Institute of
Mathematical Statistics Collections. Beachwood, OH: Institute of
Mathematical Statistics.
</div>
<div id="ref-drcplus" class="csl-entry">
Judge, Jonathan. 2019. <span>“Entirely Beyond WOWY: A Breakdown of
DRC+.”</span> <em>Baseball Prospectus</em>. <a href="https://www.baseballprospectus.com/news/article/48293/entirely-beyond-wowy-a-breakdown-of-drc/" class="external-link">https://www.baseballprospectus.com/news/article/48293/entirely-beyond-wowy-a-breakdown-of-drc/</a>.
</div>
<div id="ref-MixSQP" class="csl-entry">
Kim, Youngseok, Peter Carbonetto, Matthew Stephens, and Mihai Anitescu.
2020. <span>“A Fast Algorithm for Maximum Likelihood Estimation of
Mixture Proportions Using Sequential Quadratic Programming.”</span>
<em>Journal of Computational and Graphical Statistics</em> 29 (2):
261–73.
</div>
<div id="ref-NarasimhanEfron" class="csl-entry">
Narasimhan, Balasubramanian, and Bradley Efron. 2020.
<span>“deconvolveR: A g-Modeling Program for Deconvolution and Empirical
<span>Bayes</span> Estimation.”</span> <em>Journal of Statistical
Software</em> 94 (11): 1–20.
</div>
<div id="ref-robinson" class="csl-entry">
Robinson, David. 2017. <span>“Introduction to Empirical
<span>Bayes</span>: Examples from Baseball Statistics.”</span> <a href="https://github.com/dgrtwo/empirical-bayes-book" class="external-link">https://github.com/dgrtwo/empirical-bayes-book</a>.
</div>
<div id="ref-xwoba" class="csl-entry">
Sharpe, Sam. 2019. <span>“An Introduction to Expected Weighted
<span>O</span>n-Base Average (xwOBA).”</span> <em>MLB Technology
Blog</em>. <a href="https://technology.mlblogs.com/an-introduction-to-expected-weighted-on-base-average-xwoba-29d6070ba52b" class="external-link">https://technology.mlblogs.com/an-introduction-to-expected-weighted-on-base-average-xwoba-29d6070ba52b</a>.
</div>
<div id="ref-Tango" class="csl-entry">
Tango, T. M., M. G. Lichtman, and A. E. Dolphin. 2006. <em>The Book:
Playing the Percentages in Baseball</em>. TMA Press.
</div>
<div id="ref-ggplot2" class="csl-entry">
Wickham, Hadley. 2016. <em><span class="nocase">ggplot2</span>: Elegant
Graphics for Data Analysis</em>. New York, NY: Springer-Verlag.
</div>
<div id="ref-WillwerscheidDiss" class="csl-entry">
Willwerscheid, Jason. 2021. <span>“Empirical <span>Bayes</span> Matrix
Factorization: Methods and Applications.”</span> PhD thesis, Chicago,
IL: University of Chicago.
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Jason Willwerscheid, Matthew Stephens, Peter Carbonetto.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
