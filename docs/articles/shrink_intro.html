<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to the empirical Bayes normal means model via shrinkage estimation • ebnm</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to the empirical Bayes normal means model via shrinkage estimation">
<meta property="og:description" content="ebnm">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">ebnm</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">1.1-34</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/stephenslab/ebnm" class="external-link">Source</a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Introduction to the empirical Bayes normal means
model via shrinkage estimation</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/stephenslab/ebnm/blob/HEAD/vignettes/shrink_intro.Rmd" class="external-link"><code>vignettes/shrink_intro.Rmd</code></a></small>
      <div class="hidden name"><code>shrink_intro.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="the-normal-means-model-and-empirical-bayes">The normal means model and empirical Bayes<a class="anchor" aria-label="anchor" href="#the-normal-means-model-and-empirical-bayes"></a>
</h2>
<p>Given <span class="math inline">\(n\)</span> observations <span class="math inline">\(x_i\)</span> with known standard deviations <span class="math inline">\(s_i &gt; 0\)</span>, <span class="math inline">\(i
= 1, \dots, n\)</span>, the normal means model <span class="citation">(Robbins 1951; Efron and Morris 1972; Stephens 2017;
Bhadra et al. 2019; Johnstone 2019; Sun 2020)</span> has <span class="math display">\[\begin{equation}
x_i \overset{\text{ind.}}{\sim} \mathcal{N}(\theta_i, s_i^2),
\end{equation}\]</span> where the unknown (“true”) means <span class="math inline">\(\theta_i\)</span> are the quantities to be
estimated. Here and throughout, we use <span class="math inline">\(\mathcal{N}(\mu, \sigma^2)\)</span> to denote the
normal distribution with mean <span class="math inline">\(\mu\)</span>
and variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>The empirical Bayes (EB) approach to inferring <span class="math inline">\(\theta_i\)</span> attempts to improve upon the
maximum-likelihood estimate <span class="math inline">\(\hat{\theta}_i =
x_i\)</span> by “borrowing information” across observations, exploiting
the fact that each observation contains information not only about its
respective mean, but also about how the means are collectively
distributed <span class="citation">(Robbins 1956; Morris 1983; Efron
2010; Stephens 2017)</span>. Specifically, the empirical Bayes normal
means (EBNM) approach assumes that <span class="math display">\[\begin{equation}
\theta_i \overset{\text{ind.}}{\sim} g \in \mathcal{G},
\end{equation}\]</span> where <span class="math inline">\(\mathcal{G}\)</span> is some family of
distributions that is specified in advance and <span class="math inline">\(g \in \mathcal{G}\)</span> is estimated using the
data.</p>
<p>The EBNM model is fit by first using all of the observations to
estimate the prior <span class="math inline">\(g \in
\mathcal{G}\)</span>, and then using the estimated distribution <span class="math inline">\(\hat{g}\)</span> to compute posteriors and/or
posterior summaries for the “true” means <span class="math inline">\(\theta_i\)</span>. Commonly, <span class="math inline">\(g\)</span> is estimated via maximum-likelihood and
posterior means are used as point estimates for the unknown means. The
<strong>ebnm</strong> package provides a unified interface for
efficiently carrying out both steps, with a wide range of available
options for the prior family <span class="math inline">\(\mathcal{G}\)</span>.</p>
<p>For a detailed introduction, see our <a href="https://arxiv.org/abs/2110.00152" class="external-link">ebnm paper</a>. For further
background, see for example <a href="https://jdstorey.org/fas" class="external-link">John
Storey’s book</a>.</p>
</div>
<div class="section level2">
<h2 id="an-illustration-shrinkage-estimation">An illustration: shrinkage estimation<a class="anchor" aria-label="anchor" href="#an-illustration-shrinkage-estimation"></a>
</h2>
<p>Our example data set consists of 400 data points simulated from a
normal means model in which the true prior <span class="math inline">\(g\)</span> is a mixture of (a) a normal
distribution centered at 2 and (b) a point-mass also centered at 2:</p>
<p><span class="math display">\[
\theta_i \sim 0.8\delta_2 + 0.2 N(2,1)
\]</span></p>
<p>First, we simulate the “true” means <span class="math inline">\(\theta_i\)</span> from this prior:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">400</span></span>
<span><span class="va">u</span> <span class="op">&lt;-</span> <span class="fl">2</span> <span class="op">+</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="op">&lt;</span> <span class="fl">0.2</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></code></pre></div>
<p>Next, we simulate the observed means <span class="math inline">\(x_i\)</span> as “noisy” estimates of the true
means (in this example, the noise is homoskedastic):</p>
<p><span class="math display">\[
x_i \sim N(\theta_i,s_i), \quad s_i = 1/3,
\]</span></p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">s</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="fl">3</span>, <span class="va">n</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">u</span> <span class="op">+</span> <span class="va">s</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></span></code></pre></div>
<p>Although we know what the true means are in this example, we’ll treat
them as quantities we cannot observe.</p>
<p>The maximum-likelihood estimates (MLEs) of the true means are simply
<span class="math inline">\(\hat{u}_i = x_i\)</span>:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">lims</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.55</span>, <span class="fl">5.05</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">u</span>, <span class="va">x</span>, pch <span class="op">=</span> <span class="fl">4</span>, cex <span class="op">=</span> <span class="fl">0.75</span>, xlim <span class="op">=</span> <span class="va">lims</span>, ylim <span class="op">=</span> <span class="va">lims</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"true value"</span>, ylab <span class="op">=</span> <span class="st">"estimate"</span>, main <span class="op">=</span> <span class="st">"MLE"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fl">0</span>, b <span class="op">=</span> <span class="fl">1</span>, col <span class="op">=</span> <span class="st">"magenta"</span>, lty <span class="op">=</span> <span class="st">"dotted"</span><span class="op">)</span></span></code></pre></div>
<p><img src="shrink_intro_files/figure-html/plot-mle-1.png" width="315" style="display: block; margin: auto;"></p>
<p>We can do better than the MLE — and in fact some theory tells us we
are guaranteed to do better — by learning a prior using all the
observations, then “shrinking” the estimates toward this prior.</p>
<p>Let’s illustrate this idea with a simple normal prior in which the
mean and variance of the normal prior are learned from the data. (Note
that the normal prior is the wrong prior for this data set! Recall we
that simulated data using a mixture of a normal and a point-mass.)</p>
<p>First, we fit the prior:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/stephenslab/ebnm" class="external-link">"ebnm"</a></span><span class="op">)</span></span>
<span><span class="va">fit_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"normal"</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></span></code></pre></div>
<p>Next we estimate the true means using posterior means <span class="math inline">\(\hat{u}_i = E[\theta_i \,|\, x_i,
\hat{g}]\)</span>. We extract these posterior means using the
<code><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef()</a></code> method:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit_normal</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">u</span>, <span class="va">y</span>, pch <span class="op">=</span> <span class="fl">4</span>, cex <span class="op">=</span> <span class="fl">0.75</span>, xlim <span class="op">=</span> <span class="va">lims</span>, ylim <span class="op">=</span> <span class="va">lims</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"true value"</span>, ylab <span class="op">=</span> <span class="st">"estimate"</span>, main <span class="op">=</span> <span class="st">"normal prior"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fl">0</span>, b <span class="op">=</span> <span class="fl">1</span>, col <span class="op">=</span> <span class="st">"magenta"</span>, lty <span class="op">=</span> <span class="st">"dotted"</span><span class="op">)</span></span></code></pre></div>
<p><img src="shrink_intro_files/figure-html/plot-ebnm-normal-1.png" width="315" style="display: block; margin: auto;"></p>
<p>These “shrunken” estimates are better when true means <span class="math inline">\(\theta_i\)</span> are near 2, but worse when they
are far from 2. Still, they substantially improve the <em>overall
estimation error</em> (the “root mean-squared error” or RMSE):</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">err_mle</span>           <span class="op">&lt;-</span> <span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="va">u</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">err_shrink_normal</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="va">u</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">4</span>,</span>
<span>            x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>mle           <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">err_mle</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                  shrink_normal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">err_shrink_normal</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#           mle shrink_normal </span></span>
<span><span class="co">#        0.3599        0.2868</span></span></code></pre></div>
<p>Here’s a more detailed comparison of the estimation error:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">err_mle</span>, <span class="va">err_shrink_normal</span>, pch <span class="op">=</span> <span class="fl">4</span>, cex <span class="op">=</span> <span class="fl">0.75</span>,</span>
<span>     xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1.2</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1.2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fl">0</span>, b <span class="op">=</span> <span class="fl">1</span>, col <span class="op">=</span> <span class="st">"magenta"</span>, lty <span class="op">=</span> <span class="st">"dotted"</span><span class="op">)</span></span></code></pre></div>
<p><img src="shrink_intro_files/figure-html/plot-mse-1-1.png" width="315" style="display: block; margin: auto;"></p>
<p>Indeed, the error increases in a few of the estimates and decreases
in many of the other estimates, resulting in a lower RMSE over the 400
data points.</p>
<p>Let’s now see what happens when we use a family of priors that is
better suited to this data set — specifically, the “point-normal”
family. Notice that the only change we make in our call to
<code><a href="../reference/ebnm.html">ebnm()</a></code> is in the <code>prior_family</code> argument:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_pn</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/ebnm.html">ebnm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">s</span>, prior_family <span class="op">=</span> <span class="st">"point_normal"</span>, mode <span class="op">=</span> <span class="st">"estimate"</span><span class="op">)</span></span></code></pre></div>
<p>Now we extract the posterior mean estimates and compare to the true
values:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fit_pn</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">u</span>, <span class="va">y</span>, pch <span class="op">=</span> <span class="fl">4</span>, cex <span class="op">=</span> <span class="fl">0.75</span>, xlim <span class="op">=</span> <span class="va">lims</span>, ylim <span class="op">=</span> <span class="va">lims</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"true value"</span>, ylab <span class="op">=</span> <span class="st">"estimate"</span>, main <span class="op">=</span> <span class="st">"point-normal prior"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html" class="external-link">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fl">0</span>, b <span class="op">=</span> <span class="fl">1</span>, col <span class="op">=</span> <span class="st">"magenta"</span>, lty <span class="op">=</span> <span class="st">"dotted"</span><span class="op">)</span></span></code></pre></div>
<p><img src="shrink_intro_files/figure-html/plot-ebnm-pn-1.png" width="315" style="display: block; margin: auto;"></p>
<p>The added flexibility of the point-normal prior improves the accuracy
of estimates for means near 2, while estimates for means far from 2 are
no worse than the MLEs. The result is that the overall RMSE again sees a
substantial improvement:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">err_shrink_pn</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="va">u</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span>digits <span class="op">=</span> <span class="fl">4</span>,</span>
<span>            x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>mle <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">err_mle</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                  normal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">err_shrink_normal</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                  point_normal <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">err_shrink_pn</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#          mle       normal point_normal </span></span>
<span><span class="co">#       0.3599       0.2868       0.2100</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="session-information">Session information<a class="anchor" aria-label="anchor" href="#session-information"></a>
</h2>
<p>The following R version and packages were used to generate this
vignette:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html" class="external-link">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co"># R version 4.3.2 (2023-10-31)</span></span>
<span><span class="co"># Platform: aarch64-apple-darwin20 (64-bit)</span></span>
<span><span class="co"># Running under: macOS Monterey 12.7.4</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># Matrix products: default</span></span>
<span><span class="co"># BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib </span></span>
<span><span class="co"># LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># locale:</span></span>
<span><span class="co"># [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># time zone: America/New_York</span></span>
<span><span class="co"># tzcode source: internal</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># attached base packages:</span></span>
<span><span class="co"># [1] stats     graphics  grDevices utils     datasets  methods   base     </span></span>
<span><span class="co"># </span></span>
<span><span class="co"># other attached packages:</span></span>
<span><span class="co"># [1] ebnm_1.1-34</span></span>
<span><span class="co"># </span></span>
<span><span class="co"># loaded via a namespace (and not attached):</span></span>
<span><span class="co">#  [1] sass_0.4.8        utf8_1.2.4        generics_0.1.3    ashr_2.2-63      </span></span>
<span><span class="co">#  [5] stringi_1.8.3     lattice_0.21-9    digest_0.6.34     magrittr_2.0.3   </span></span>
<span><span class="co">#  [9] evaluate_0.23     grid_4.3.2        fastmap_1.1.1     jsonlite_1.8.8   </span></span>
<span><span class="co"># [13] Matrix_1.6-1.1    mixsqp_0.3-54     purrr_1.0.2       fansi_1.0.6      </span></span>
<span><span class="co"># [17] scales_1.3.0      truncnorm_1.0-9   invgamma_1.1      textshaping_0.3.7</span></span>
<span><span class="co"># [21] jquerylib_0.1.4   cli_3.6.2         rlang_1.1.3       deconvolveR_1.2-1</span></span>
<span><span class="co"># [25] munsell_0.5.0     splines_4.3.2     cachem_1.0.8      yaml_2.3.8       </span></span>
<span><span class="co"># [29] tools_4.3.2       SQUAREM_2021.1    memoise_2.0.1     dplyr_1.1.4      </span></span>
<span><span class="co"># [33] colorspace_2.1-0  ggplot2_3.5.0     vctrs_0.6.5       R6_2.5.1         </span></span>
<span><span class="co"># [37] lifecycle_1.0.4   stringr_1.5.1     fs_1.6.3          trust_0.1-8      </span></span>
<span><span class="co"># [41] ragg_1.2.7        irlba_2.3.5.1     pkgconfig_2.0.3   desc_1.4.3       </span></span>
<span><span class="co"># [45] pkgdown_2.0.7     bslib_0.6.1       pillar_1.9.0      gtable_0.3.4     </span></span>
<span><span class="co"># [49] glue_1.7.0        Rcpp_1.0.12       systemfonts_1.0.5 xfun_0.41        </span></span>
<span><span class="co"># [53] tibble_3.2.1      tidyselect_1.2.1  highr_0.10        rstudioapi_0.15.0</span></span>
<span><span class="co"># [57] knitr_1.45        htmltools_0.5.7   rmarkdown_2.25    compiler_4.3.2   </span></span>
<span><span class="co"># [61] horseshoe_0.2.0</span></span></code></pre></div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bhadra2019lasso" class="csl-entry">
Bhadra, Anindya, Jyotishka Datta, Nicholas G. Polson, and Brandon
Willard. 2019. <span>“Lasso Meets Horseshoe: A Survey.”</span>
<em>Statistical Science</em> 34 (3): 405–27.
</div>
<div id="ref-Efron_Book" class="csl-entry">
Efron, Bradley. 2010. <em>Large-Scale Inference: Empirical
<span>Bayes</span> Methods for Estimation, Testing, and Prediction</em>.
Vol. 1. Institute of Mathematical Statistics Monographs. Cambridge, UK:
Cambridge University Press.
</div>
<div id="ref-efron1972limiting" class="csl-entry">
Efron, Bradley, and Carl Morris. 1972. <span>“Limiting the Risk of
<span>Bayes</span> and Empirical <span>Bayes</span>
Estimators—<span>Part</span> <span>II</span>: The Empirical
<span>Bayes</span> Case.”</span> <em>Journal of the American Statistical
Association</em> 67 (337): 130–39.
</div>
<div id="ref-Johnstone" class="csl-entry">
Johnstone, Iain. 2019. <span>“Gaussian Estimation: Sequence and Wavelet
Models.”</span> <a href="https://imjohnstone.su.domains/" class="external-link">https://imjohnstone.su.domains/</a>.
</div>
<div id="ref-Morris" class="csl-entry">
Morris, Carl N. 1983. <span>“Parametric Empirical <span>Bayes</span>
Inference: Theory and Applications.”</span> <em>Journal of the American
Statistical Association</em> 78 (381): 47–55.
</div>
<div id="ref-Robbins51" class="csl-entry">
Robbins, Herbert. 1951. <span>“Asymptotically Subminimax Solutions of
Compound Statistical Decision Problems.”</span> In <em>Proceedings of
the <span>S</span>econd <span>B</span>erkeley <span>S</span>ymposium on
<span>M</span>athematical <span>S</span>tatistics and
<span>P</span>robability, 1951, Vol. <span>II</span></em>, 131–49.
University of California Press, Berkeley; Los Angeles, CA.
</div>
<div id="ref-Robbins56" class="csl-entry">
———. 1956. <span>“An Empirical <span>B</span>ayes Approach to
Statistics.”</span> In <em>Proceedings of the <span>T</span>hird
<span>B</span>erkeley <span>S</span>ymposium on
<span>M</span>athematical <span>S</span>tatistics and
<span>P</span>robability, 1956, Vol. <span>I</span></em>, 157–63.
University of California Press, Berkeley; Los Angeles, CA.
</div>
<div id="ref-Stephens_NewDeal" class="csl-entry">
Stephens, Matthew. 2017. <span>“False Discovery Rates: A New
Deal.”</span> <em>Biostatistics</em> 18 (2): 275–94.
</div>
<div id="ref-lei-thesis" class="csl-entry">
Sun, Lei. 2020. <span>“Topics on Empirical Bayes Normal Means.”</span>
PhD thesis, Chicago, IL: University of Chicago.
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Jason Willwerscheid, Matthew Stephens, Peter Carbonetto.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
